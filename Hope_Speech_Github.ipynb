{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AieCCFgLohX4",
        "outputId": "18fe5465-6eea-4688-b394-b6c332761131"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile requirements.txt\n",
        "bert-score==0.3.7\n",
        "chardet==4.0.0\n",
        "click==7.1.2\n",
        "cycler==0.10.0\n",
        "dataclasses\n",
        "datasets==1.3.0\n",
        "dill==0.3.3\n",
        "filelock==3.0.12\n",
        "fsspec==0.8.7\n",
        "gensim==3.8.3\n",
        "huggingface-hub==0.0.2\n",
        "idna==2.10\n",
        "importlib-metadata==3.7.0\n",
        "joblib==1.0.1\n",
        "jsonlines==2.0.0\n",
        "kiwisolver==1.3.1\n",
        "matplotlib==3.3.4\n",
        "multiprocess==0.70.11.1\n",
        "nltk==3.5\n",
        "numpy==1.19.5\n",
        "packaging==20.9\n",
        "pandas==1.1.5\n",
        "pillow==8.1.0\n",
        "pyarrow==3.0.0\n",
        "pyparsing==2.4.7\n",
        "python-dateutil==2.8.1\n",
        "pytz==2021.1\n",
        "regex==2020.11.13\n",
        "requests==2.25.1\n",
        "sacremoses==0.0.43\n",
        "scikit-learn==0.24.1\n",
        "scipy==1.5.4\n",
        "six==1.15.0\n",
        "sklearn==0.0\n",
        "smart-open==4.2.0\n",
        "threadpoolctl==2.1.0\n",
        "tokenizers==0.10.1\n",
        "torch==1.7.1\n",
        "tqdm==4.49.0\n",
        "transformers==4.3.3\n",
        "typing-extensions==3.7.4.3\n",
        "urllib3==1.26.3\n",
        "xxhash==2.0.0\n",
        "zipp==3.4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fa9I0qC7ojlU",
        "outputId": "bbb2617c-537b-4166-875a-c8d033930ca0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting bert-score==0.3.7\n",
            "  Downloading bert_score-0.3.7-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting chardet==4.0.0\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[K     |████████████████████████████████| 178 kB 9.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (7.1.2)\n",
            "Collecting cycler==0.10.0\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Collecting datasets==1.3.0\n",
            "  Downloading datasets-1.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 41.8 MB/s \n",
            "\u001b[?25hCollecting dill==0.3.3\n",
            "  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.7 MB/s \n",
            "\u001b[?25hCollecting filelock==3.0.12\n",
            "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
            "Collecting fsspec==0.8.7\n",
            "  Downloading fsspec-0.8.7-py3-none-any.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 34.3 MB/s \n",
            "\u001b[?25hCollecting gensim==3.8.3\n",
            "  Downloading gensim-3.8.3-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2 MB 1.8 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.2\n",
            "  Downloading huggingface_hub-0.0.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (2.10)\n",
            "Collecting importlib-metadata==3.7.0\n",
            "  Downloading importlib_metadata-3.7.0-py3-none-any.whl (11 kB)\n",
            "Collecting joblib==1.0.1\n",
            "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
            "\u001b[K     |████████████████████████████████| 303 kB 46.0 MB/s \n",
            "\u001b[?25hCollecting jsonlines==2.0.0\n",
            "  Downloading jsonlines-2.0.0-py3-none-any.whl (6.3 kB)\n",
            "Collecting kiwisolver==1.3.1\n",
            "  Downloading kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 41.5 MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.3.4\n",
            "  Downloading matplotlib-3.3.4-cp37-cp37m-manylinux1_x86_64.whl (11.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.5 MB 26.0 MB/s \n",
            "\u001b[?25hCollecting multiprocess==0.70.11.1\n",
            "  Downloading multiprocess-0.70.11.1-py37-none-any.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 49.1 MB/s \n",
            "\u001b[?25hCollecting nltk==3.5\n",
            "  Downloading nltk-3.5.zip (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 38.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (1.19.5)\n",
            "Collecting packaging==20.9\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas==1.1.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 22)) (1.1.5)\n",
            "Collecting pillow==8.1.0\n",
            "  Downloading Pillow-8.1.0-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 34.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow==3.0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 24)) (3.0.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting python-dateutil==2.8.1\n",
            "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
            "\u001b[K     |████████████████████████████████| 227 kB 48.7 MB/s \n",
            "\u001b[?25hCollecting pytz==2021.1\n",
            "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
            "\u001b[K     |████████████████████████████████| 510 kB 49.0 MB/s \n",
            "\u001b[?25hCollecting regex==2020.11.13\n",
            "  Downloading regex-2020.11.13-cp37-cp37m-manylinux2014_x86_64.whl (719 kB)\n",
            "\u001b[K     |████████████████████████████████| 719 kB 47.8 MB/s \n",
            "\u001b[?25hCollecting requests==2.25.1\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting sacremoses==0.0.43\n",
            "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
            "\u001b[K     |████████████████████████████████| 883 kB 38.8 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.24.1\n",
            "  Downloading scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 31.6 MB/s \n",
            "\u001b[?25hCollecting scipy==1.5.4\n",
            "  Downloading scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 45.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six==1.15.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 33)) (1.15.0)\n",
            "Requirement already satisfied: sklearn==0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 34)) (0.0)\n",
            "Collecting smart-open==4.2.0\n",
            "  Downloading smart_open-4.2.0.tar.gz (119 kB)\n",
            "\u001b[K     |████████████████████████████████| 119 kB 40.0 MB/s \n",
            "\u001b[?25hCollecting threadpoolctl==2.1.0\n",
            "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
            "Collecting tokenizers==0.10.1\n",
            "  Downloading tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 24.2 MB/s \n",
            "\u001b[?25hCollecting torch==1.7.1\n",
            "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8 MB 17 kB/s \n",
            "\u001b[?25hCollecting tqdm==4.49.0\n",
            "  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 7.5 MB/s \n",
            "\u001b[?25hCollecting transformers==4.3.3\n",
            "  Downloading transformers-4.3.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 36.2 MB/s \n",
            "\u001b[?25hCollecting typing-extensions==3.7.4.3\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting urllib3==1.26.3\n",
            "  Downloading urllib3-1.26.3-py2.py3-none-any.whl (137 kB)\n",
            "\u001b[K     |████████████████████████████████| 137 kB 47.9 MB/s \n",
            "\u001b[?25hCollecting xxhash==2.0.0\n",
            "  Downloading xxhash-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 50.4 MB/s \n",
            "\u001b[?25hCollecting zipp==3.4.0\n",
            "  Downloading zipp-3.4.0-py3-none-any.whl (5.2 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->-r requirements.txt (line 29)) (2021.10.8)\n",
            "Building wheels for collected packages: nltk, sacremoses, smart-open\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434690 sha256=79ce2f962ef061514d1e19704a16cec1c82d9bed67c6128f7646b38f0fd370a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/6c/46/a1865e7ba706b3817f5d1b2ff7ce8996aabdd0d03d47ba0266\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893249 sha256=6b6e753660b0847a4e25cbcfa6a33ee43899974181357892947daee3b826582b\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/09/d1/bf058f7d6fa0ecba2ce7c66be3b8d012beb4bf61a6e0c101c0\n",
            "  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for smart-open: filename=smart_open-4.2.0-py3-none-any.whl size=109645 sha256=0eb1eb1718e8581f19a215412b8c2a345884ffbbd5b4c4bb40e406c53b100002\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/88/e3/7cd51a6379cac37213cac47545a27688782752ff66351b953d\n",
            "Successfully built nltk sacremoses smart-open\n",
            "Installing collected packages: zipp, urllib3, typing-extensions, tqdm, regex, pyparsing, joblib, chardet, tokenizers, threadpoolctl, scipy, sacremoses, requests, pytz, python-dateutil, pillow, packaging, kiwisolver, importlib-metadata, filelock, dill, cycler, xxhash, transformers, torch, smart-open, scikit-learn, multiprocess, matplotlib, huggingface-hub, fsspec, nltk, jsonlines, gensim, datasets, dataclasses, bert-score\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.7.0\n",
            "    Uninstalling zipp-3.7.0:\n",
            "      Successfully uninstalled zipp-3.7.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.10.0.2\n",
            "    Uninstalling typing-extensions-3.10.0.2:\n",
            "      Successfully uninstalled typing-extensions-3.10.0.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.3\n",
            "    Uninstalling tqdm-4.62.3:\n",
            "      Successfully uninstalled tqdm-4.62.3\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.7\n",
            "    Uninstalling pyparsing-3.0.7:\n",
            "      Successfully uninstalled pyparsing-3.0.7\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.1.0\n",
            "    Uninstalling joblib-1.1.0:\n",
            "      Successfully uninstalled joblib-1.1.0\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 3.0.4\n",
            "    Uninstalling chardet-3.0.4:\n",
            "      Successfully uninstalled chardet-3.0.4\n",
            "  Attempting uninstall: threadpoolctl\n",
            "    Found existing installation: threadpoolctl 3.0.0\n",
            "    Uninstalling threadpoolctl-3.0.0:\n",
            "      Successfully uninstalled threadpoolctl-3.0.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 21.3\n",
            "    Uninstalling packaging-21.3:\n",
            "      Successfully uninstalled packaging-21.3\n",
            "  Attempting uninstall: kiwisolver\n",
            "    Found existing installation: kiwisolver 1.3.2\n",
            "    Uninstalling kiwisolver-1.3.2:\n",
            "      Successfully uninstalled kiwisolver-1.3.2\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.10.1\n",
            "    Uninstalling importlib-metadata-4.10.1:\n",
            "      Successfully uninstalled importlib-metadata-4.10.1\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.4.2\n",
            "    Uninstalling filelock-3.4.2:\n",
            "      Successfully uninstalled filelock-3.4.2\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 5.2.1\n",
            "    Uninstalling smart-open-5.2.1:\n",
            "      Successfully uninstalled smart-open-5.2.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.12.2\n",
            "    Uninstalling multiprocess-0.70.12.2:\n",
            "      Successfully uninstalled multiprocess-0.70.12.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\n",
            "markdown 3.3.6 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 3.7.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.25.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed bert-score-0.3.7 chardet-4.0.0 cycler-0.10.0 dataclasses-0.6 datasets-1.3.0 dill-0.3.3 filelock-3.0.12 fsspec-0.8.7 gensim-3.8.3 huggingface-hub-0.0.2 importlib-metadata-3.7.0 joblib-1.0.1 jsonlines-2.0.0 kiwisolver-1.3.1 matplotlib-3.3.4 multiprocess-0.70.11.1 nltk-3.5 packaging-20.9 pillow-8.1.0 pyparsing-2.4.7 python-dateutil-2.8.1 pytz-2021.1 regex-2020.11.13 requests-2.25.1 sacremoses-0.0.43 scikit-learn-0.24.1 scipy-1.5.4 smart-open-4.2.0 threadpoolctl-2.1.0 tokenizers-0.10.1 torch-1.7.1 tqdm-4.49.0 transformers-4.3.3 typing-extensions-3.7.4.3 urllib3-1.26.3 xxhash-2.0.0 zipp-3.4.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "cycler",
                  "dateutil",
                  "kiwisolver",
                  "matplotlib",
                  "mpl_toolkits",
                  "pyparsing",
                  "pytz"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoDzvDUhvWgG",
        "outputId": "7283255b-c892-4125-ef03-76532b999829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 1CDu_lgUZ6wo67zogtC7n2x5UGH_HmUEK into /content/Hope_tam_train.csv... Done.\n",
            "Downloading 1OrytE0j5wozfEAnx8L4pN1c53iqKRydw into /content/Hope_tam_dev.csv... Done.\n"
          ]
        }
      ],
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='1CDu_lgUZ6wo67zogtC7n2x5UGH_HmUEK', dest_path='/content/Hope_tam_train.csv')\n",
        "gdd.download_file_from_google_drive(file_id='1OrytE0j5wozfEAnx8L4pN1c53iqKRydw', dest_path='/content/Hope_tam_dev.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXA5vTpy1mC0",
        "outputId": "7fae628e-9c2d-4e75-a121-8c99ff87d94e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 17YUj2Roughk0K3GBu4b6dMWevk9-xWod into /content/Hope_ENG_new_test.csv... Done.\n"
          ]
        }
      ],
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "# gdd.download_file_from_google_drive(file_id='1LRTart15TZkuIo_sk3iWUbgLt1Ro71kN', dest_path='/content/Hope_ENG_test.csv')\n",
        "gdd.download_file_from_google_drive(file_id='17YUj2Roughk0K3GBu4b6dMWevk9-xWod', dest_path='/content/Hope_ENG_new_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoOoPWNkw5QT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Hope_tam_train.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KxwBnGpe3iaY",
        "outputId": "e1ee7bf2-fb50-4226-b9c6-dbb78005d492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  I also don't have tiktok hello and allnBut I'm using xiaomi      Hope_speech\n",
              "0  Thalaivare..neengale inum one plus mobile vach...           Non_hope_speech\n",
              "1  Annee varanda thondai.. corona virus affect pa...               Hope_speech\n",
              "2                                 5views but 18likes           Non_hope_speech\n",
              "3  China phone vakathiga inu evanga ellam tiktok ...           Non_hope_speech\n",
              "4                           Cisco webex meetings bro           Non_hope_speech"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-032c37e3-96a9-4f4d-8da3-89d10bf97502\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>I also don't have tiktok hello and allnBut I'm using xiaomi</th>\n",
              "      <th>Hope_speech</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Thalaivare..neengale inum one plus mobile vach...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Annee varanda thondai.. corona virus affect pa...</td>\n",
              "      <td>Hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5views but 18likes</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>China phone vakathiga inu evanga ellam tiktok ...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cisco webex meetings bro</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-032c37e3-96a9-4f4d-8da3-89d10bf97502')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-032c37e3-96a9-4f4d-8da3-89d10bf97502 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-032c37e3-96a9-4f4d-8da3-89d10bf97502');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Hope_speech'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhbImdLQ4jwZ",
        "outputId": "e2de0c9e-dc0f-47e6-b4eb-a1ef52153aa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Non_hope_speech    7872\n",
              "Hope_speech        6326\n",
              "Name: Hope_speech, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DngJxub87SEq",
        "outputId": "e53d5230-3fd1-45b5-b84d-1a873a8e4dbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UANllvDXxJm-"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('/content/drive/MyDrive/Kaggle/Tweet_shared_task/df_train_preprocessed.csv')\n",
        "df_dev = pd.read_csv('/content/drive/MyDrive/Kaggle/Tweet_shared_task/df_dev_preprocessed.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6ITW-4kZt2lQ",
        "outputId": "6a84cc36-abb7-4efa-9c18-d851217d8af8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a8ec3a85-5fbe-4e7b-9bea-e21db1f1b5cc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Thats it.... like....I dont like that statue</th>\n",
              "      <th>Non_hope_speech</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@Generation X Counting money that she been giv...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@Paola Hernandez i never said to be intolerant...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@Firstlast300 Wow An opinion is that I don't l...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WOW!!!!!!!That was so so inspiring and incredi...</td>\n",
              "      <td>Hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@FALC0n  Yea sorry I know Asian is an ethnicit...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8ec3a85-5fbe-4e7b-9bea-e21db1f1b5cc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a8ec3a85-5fbe-4e7b-9bea-e21db1f1b5cc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a8ec3a85-5fbe-4e7b-9bea-e21db1f1b5cc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        Thats it.... like....I dont like that statue  Non_hope_speech\n",
              "0  @Generation X Counting money that she been giv...  Non_hope_speech\n",
              "1  @Paola Hernandez i never said to be intolerant...  Non_hope_speech\n",
              "2  @Firstlast300 Wow An opinion is that I don't l...  Non_hope_speech\n",
              "3  WOW!!!!!!!That was so so inspiring and incredi...      Hope_speech\n",
              "4  @FALC0n  Yea sorry I know Asian is an ethnicit...  Non_hope_speech"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_dev.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "mhNT2r7F16gO",
        "outputId": "f0f4f977-23b2-4165-fd40-3c17096aed92"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-37a0e80b-b96a-4b34-9403-b8f0eef52626\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>These Abandon Hope videos only cement my pessimism towards humanity. Ugh</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow your videos are long. They have good points</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I know this is none of my business but 75k+ in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hope? Is that a new Pokémon?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Almost every time someone depicts a davidian s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>how can you disrespect your own body? It is YO...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37a0e80b-b96a-4b34-9403-b8f0eef52626')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-37a0e80b-b96a-4b34-9403-b8f0eef52626 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-37a0e80b-b96a-4b34-9403-b8f0eef52626');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  These Abandon Hope videos only cement my pessimism towards humanity. Ugh\n",
              "0    Wow your videos are long. They have good points                      \n",
              "1  I know this is none of my business but 75k+ in...                      \n",
              "2                       Hope? Is that a new Pokémon?                      \n",
              "3  Almost every time someone depicts a davidian s...                      \n",
              "4  how can you disrespect your own body? It is YO...                      "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test = pd.read_csv('/content/Hope_ENG_new_test.csv')\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2F_lqW53VIIr"
      },
      "outputs": [],
      "source": [
        "train_tweet = list(df_train['these tiktoks radiate gay chaotic energy and i love it'])\n",
        "train_tweet.append('these tiktoks radiate gay chaotic energy and i love it')\n",
        "train_label = list(df_train['Non_hope_speech'])\n",
        "train_label.append('Non_hope_speech')\n",
        "dev_tweet = list(df_dev['Thats it.... like....I dont like that statue'])\n",
        "dev_tweet.append('Thats it.... like....I dont like that statue')\n",
        "dev_label = list(df_dev['Non_hope_speech'])\n",
        "dev_label.append('Non_hope_speech')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3Q54VLo2E5_"
      },
      "outputs": [],
      "source": [
        "test_tweet = ['These Abandon Hope videos only cement my pessimism towards humanity. Ugh']\n",
        "test_tweet+=df_test['These Abandon Hope videos only cement my pessimism towards humanity. Ugh']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHpW5eyRZT8p"
      },
      "outputs": [],
      "source": [
        "df_train = pd.DataFrame(data={'tweet':train_tweet,'label':train_label})\n",
        "df_dev = pd.DataFrame(data={'tweet':dev_tweet,'label':dev_label})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9MOunhe54P0"
      },
      "outputs": [],
      "source": [
        "df_test = pd.DataFrame(data={'tweet':test_tweet})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eK5uNoTeV-3q",
        "outputId": "2b850465-9185-49cb-9152-df8aa15681df"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b9f5a37c-d7a1-41f7-89af-dc9e20bc9c23\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@Champions Again He got killed for using false...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It's not that all lives don't matter</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Is it really that difficult to understand? Bla...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Whenever we say black isn't that racists?  Why...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ros The Boss u don’t know that she’s actually ...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9f5a37c-d7a1-41f7-89af-dc9e20bc9c23')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b9f5a37c-d7a1-41f7-89af-dc9e20bc9c23 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b9f5a37c-d7a1-41f7-89af-dc9e20bc9c23');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               tweet            label\n",
              "0  @Champions Again He got killed for using false...  Non_hope_speech\n",
              "1               It's not that all lives don't matter  Non_hope_speech\n",
              "2  Is it really that difficult to understand? Bla...  Non_hope_speech\n",
              "3  Whenever we say black isn't that racists?  Why...  Non_hope_speech\n",
              "4  Ros The Boss u don’t know that she’s actually ...  Non_hope_speech"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZHKKCWGXdpy"
      },
      "outputs": [],
      "source": [
        "df_train['tweet'] = df_train.tweet.str.lower()\n",
        "df_dev['tweet'] = df_dev.tweet.str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7dnFo6M5yqE"
      },
      "outputs": [],
      "source": [
        "df_test['tweet'] = df_test.tweet.str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cF2ZLE_ljlqw"
      },
      "outputs": [],
      "source": [
        "# 1. Check with/without punctuation\n",
        "# 2. Replace emojis with text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvWzek5xfKAU"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'EMOJI', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSH0vAi4h-wg"
      },
      "outputs": [],
      "source": [
        "def remove_HTML(text):\n",
        "    html=re.compile(r'<.*?>')\n",
        "    return html.sub(r'USER',text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlV7MpuWiWAJ"
      },
      "outputs": [],
      "source": [
        "def remove_URL(text):\n",
        "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url.sub(r'URL',text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34XOVv_pi2B3"
      },
      "source": [
        "Used in train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YP-qnH-9CwWI"
      },
      "outputs": [],
      "source": [
        "def remove_mention(text):\n",
        "    at=re.compile(r'@\\S+')\n",
        "    return at.sub(r'',text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dmdz4sa4ihpO"
      },
      "outputs": [],
      "source": [
        "def remove_repeat_punct(text):\n",
        "    rep = re.compile(r'([!?.]){2,}')\n",
        "    return rep.sub(r'\\1', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVtr6Moti7oX"
      },
      "outputs": [],
      "source": [
        "def remove_elongated_words(text):\n",
        "    rep = re.compile(r'\\b(\\S*?)([a-z])\\2{2,}\\b')\n",
        "    return rep.sub(r'\\1\\2', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6S6J9PtjKG5"
      },
      "outputs": [],
      "source": [
        "def transcription_smile(text):\n",
        "    eyes = \"[8:=;]\"\n",
        "    nose = \"['`\\-]\"\n",
        "    smiley = re.compile(r'[8:=;][\\'\\-]?[)dDp]')\n",
        "    return smiley.sub(r'', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N06vC_exjXty"
      },
      "outputs": [],
      "source": [
        "def transcription_sad(text):\n",
        "    eyes = \"[8:=;]\"\n",
        "    nose = \"['`\\-]\"\n",
        "    smiley = re.compile(r'[8:=;][\\'\\-]?[(\\\\/]')\n",
        "    return smiley.sub(r'', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIFrVdfRjadC"
      },
      "outputs": [],
      "source": [
        "def transcription_heart(text):\n",
        "    heart = re.compile(r'<3')\n",
        "    return heart.sub(r'', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1jHdbYIjytD"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "def remove_all_punct(text):\n",
        "    table = str.maketrans('','',string.punctuation)\n",
        "    return text.translate(table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHuHsUX52zNv"
      },
      "outputs": [],
      "source": [
        "def remove_not_ASCII(text):\n",
        "    text = ''.join([word for word in text if word in string.printable])\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mie6ZoxKDCal"
      },
      "outputs": [],
      "source": [
        "abbreviations = {\n",
        "    \"$\" : \" dollar \",\n",
        "    \"€\" : \" euro \",\n",
        "    \"4ao\" : \"for adults only\",\n",
        "    \"a.m\" : \"before midday\",\n",
        "    \"a3\" : \"anytime anywhere anyplace\",\n",
        "    \"aamof\" : \"as a matter of fact\",\n",
        "    \"acct\" : \"account\",\n",
        "    \"adih\" : \"another day in hell\",\n",
        "    \"afaic\" : \"as far as i am concerned\",\n",
        "    \"afaict\" : \"as far as i can tell\",\n",
        "    \"afaik\" : \"as far as i know\",\n",
        "    \"afair\" : \"as far as i remember\",\n",
        "    \"afk\" : \"away from keyboard\",\n",
        "    \"app\" : \"application\",\n",
        "    \"approx\" : \"approximately\",\n",
        "    \"apps\" : \"applications\",\n",
        "    \"asap\" : \"as soon as possible\",\n",
        "    \"asl\" : \"age, sex, location\",\n",
        "    \"atk\" : \"at the keyboard\",\n",
        "    \"ave.\" : \"avenue\",\n",
        "    \"aymm\" : \"are you my mother\",\n",
        "    \"ayor\" : \"at your own risk\", \n",
        "    \"b&b\" : \"bed and breakfast\",\n",
        "    \"b+b\" : \"bed and breakfast\",\n",
        "    \"b.c\" : \"before christ\",\n",
        "    \"b2b\" : \"business to business\",\n",
        "    \"b2c\" : \"business to customer\",\n",
        "    \"b4\" : \"before\",\n",
        "    \"b4n\" : \"bye for now\",\n",
        "    \"b@u\" : \"back at you\",\n",
        "    \"bae\" : \"before anyone else\",\n",
        "    \"bak\" : \"back at keyboard\",\n",
        "    \"bbbg\" : \"bye bye be good\",\n",
        "    \"bbc\" : \"british broadcasting corporation\",\n",
        "    \"bbias\" : \"be back in a second\",\n",
        "    \"bbl\" : \"be back later\",\n",
        "    \"bbs\" : \"be back soon\",\n",
        "    \"be4\" : \"before\",\n",
        "    \"bfn\" : \"bye for now\",\n",
        "    \"blvd\" : \"boulevard\",\n",
        "    \"bout\" : \"about\",\n",
        "    \"brb\" : \"be right back\",\n",
        "    \"bros\" : \"brothers\",\n",
        "    \"brt\" : \"be right there\",\n",
        "    \"bsaaw\" : \"big smile and a wink\",\n",
        "    \"btw\" : \"by the way\",\n",
        "    \"bwl\" : \"bursting with laughter\",\n",
        "    \"c/o\" : \"care of\",\n",
        "    \"cet\" : \"central european time\",\n",
        "    \"cf\" : \"compare\",\n",
        "    \"cia\" : \"central intelligence agency\",\n",
        "    \"csl\" : \"can not stop laughing\",\n",
        "    \"cu\" : \"see you\",\n",
        "    \"cul8r\" : \"see you later\",\n",
        "    \"cv\" : \"curriculum vitae\",\n",
        "    \"cwot\" : \"complete waste of time\",\n",
        "    \"cya\" : \"see you\",\n",
        "    \"cyt\" : \"see you tomorrow\",\n",
        "    \"dae\" : \"does anyone else\",\n",
        "    \"dbmib\" : \"do not bother me i am busy\",\n",
        "    \"diy\" : \"do it yourself\",\n",
        "    \"dm\" : \"direct message\",\n",
        "    \"dwh\" : \"during work hours\",\n",
        "    \"e123\" : \"easy as one two three\",\n",
        "    \"eet\" : \"eastern european time\",\n",
        "    \"eg\" : \"example\",\n",
        "    \"embm\" : \"early morning business meeting\",\n",
        "    \"encl\" : \"enclosed\",\n",
        "    \"encl.\" : \"enclosed\",\n",
        "    \"etc\" : \"and so on\",\n",
        "    \"faq\" : \"frequently asked questions\",\n",
        "    \"fawc\" : \"for anyone who cares\",\n",
        "    \"fb\" : \"facebook\",\n",
        "    \"fc\" : \"fingers crossed\",\n",
        "    \"fig\" : \"figure\",\n",
        "    \"fimh\" : \"forever in my heart\", \n",
        "    \"ft.\" : \"feet\",\n",
        "    \"ft\" : \"featuring\",\n",
        "    \"ftl\" : \"for the loss\",\n",
        "    \"ftw\" : \"for the win\",\n",
        "    \"fwiw\" : \"for what it is worth\",\n",
        "    \"fyi\" : \"for your information\",\n",
        "    \"g9\" : \"genius\",\n",
        "    \"gahoy\" : \"get a hold of yourself\",\n",
        "    \"gal\" : \"get a life\",\n",
        "    \"gcse\" : \"general certificate of secondary education\",\n",
        "    \"gfn\" : \"gone for now\",\n",
        "    \"gg\" : \"good game\",\n",
        "    \"gl\" : \"good luck\",\n",
        "    \"glhf\" : \"good luck have fun\",\n",
        "    \"gmt\" : \"greenwich mean time\",\n",
        "    \"gmta\" : \"great minds think alike\",\n",
        "    \"gn\" : \"good night\",\n",
        "    \"g.o.a.t\" : \"greatest of all time\",\n",
        "    \"goat\" : \"greatest of all time\",\n",
        "    \"goi\" : \"get over it\",\n",
        "    \"gps\" : \"global positioning system\",\n",
        "    \"gr8\" : \"great\",\n",
        "    \"gratz\" : \"congratulations\",\n",
        "    \"gyal\" : \"girl\",\n",
        "    \"h&c\" : \"hot and cold\",\n",
        "    \"hp\" : \"horsepower\",\n",
        "    \"hr\" : \"hour\",\n",
        "    \"hrh\" : \"his royal highness\",\n",
        "    \"ht\" : \"height\",\n",
        "    \"ibrb\" : \"i will be right back\",\n",
        "    \"ic\" : \"i see\",\n",
        "    \"icq\" : \"i seek you\",\n",
        "    \"icymi\" : \"in case you missed it\",\n",
        "    \"idc\" : \"i do not care\",\n",
        "    \"idgadf\" : \"i do not give a damn fuck\",\n",
        "    \"idgaf\" : \"i do not give a fuck\",\n",
        "    \"idk\" : \"i do not know\",\n",
        "    \"ie\" : \"that is\",\n",
        "    \"i.e\" : \"that is\",\n",
        "    \"ifyp\" : \"i feel your pain\",\n",
        "    \"IG\" : \"instagram\",\n",
        "    \"iirc\" : \"if i remember correctly\",\n",
        "    \"ilu\" : \"i love you\",\n",
        "    \"ily\" : \"i love you\",\n",
        "    \"imho\" : \"in my humble opinion\",\n",
        "    \"imo\" : \"in my opinion\",\n",
        "    \"imu\" : \"i miss you\",\n",
        "    \"iow\" : \"in other words\",\n",
        "    \"irl\" : \"in real life\",\n",
        "    \"j4f\" : \"just for fun\",\n",
        "    \"jic\" : \"just in case\",\n",
        "    \"jk\" : \"just kidding\",\n",
        "    \"jsyk\" : \"just so you know\",\n",
        "    \"l8r\" : \"later\",\n",
        "    \"la\" : \"los angeles\",\n",
        "    \"lb\" : \"pound\",\n",
        "    \"lbs\" : \"pounds\",\n",
        "    \"ldr\" : \"long distance relationship\",\n",
        "    \"lmao\" : \"laugh my ass off\",\n",
        "    \"lmfao\" : \"laugh my fucking ass off\",\n",
        "    \"lol\" : \"laughing out loud\",\n",
        "    \"ltd\" : \"limited\",\n",
        "    \"ltns\" : \"long time no see\",\n",
        "    \"m8\" : \"mate\",\n",
        "    \"mf\" : \"motherfucker\",\n",
        "    \"mfs\" : \"motherfuckers\",\n",
        "    \"mfw\" : \"my face when\",\n",
        "    \"mofo\" : \"motherfucker\",\n",
        "    \"mph\" : \"miles per hour\",\n",
        "    \"mr\" : \"mister\",\n",
        "    \"mrw\" : \"my reaction when\",\n",
        "    \"ms\" : \"miss\",\n",
        "    \"mte\" : \"my thoughts exactly\",\n",
        "    \"nagi\" : \"not a good idea\",\n",
        "    \"nbc\" : \"national broadcasting company\",\n",
        "    \"nbd\" : \"not big deal\",\n",
        "    \"nfs\" : \"not for sale\",\n",
        "    \"ngl\" : \"not going to lie\",\n",
        "    \"nhs\" : \"national health service\",\n",
        "    \"nrn\" : \"no reply necessary\",\n",
        "    \"nsfl\" : \"not safe for life\",\n",
        "    \"nsfw\" : \"not safe for work\",\n",
        "    \"nth\" : \"nice to have\",\n",
        "    \"nvr\" : \"never\",\n",
        "    \"nyc\" : \"new york city\",\n",
        "    \"oc\" : \"original content\",\n",
        "    \"og\" : \"original\",\n",
        "    \"ohp\" : \"overhead projector\",\n",
        "    \"oic\" : \"oh i see\",\n",
        "    \"omdb\" : \"over my dead body\",\n",
        "    \"omg\" : \"oh my god\",\n",
        "    \"omw\" : \"on my way\",\n",
        "    \"p.a\" : \"per annum\",\n",
        "    \"p.m\" : \"after midday\",\n",
        "    \"pm\" : \"prime minister\",\n",
        "    \"poc\" : \"people of color\",\n",
        "    \"pov\" : \"point of view\",\n",
        "    \"pp\" : \"pages\",\n",
        "    \"ppl\" : \"people\",\n",
        "    \"prw\" : \"parents are watching\",\n",
        "    \"ps\" : \"postscript\",\n",
        "    \"pt\" : \"point\",\n",
        "    \"ptb\" : \"please text back\",\n",
        "    \"pto\" : \"please turn over\",\n",
        "    \"qpsa\" : \"what happens\", #\"que pasa\",\n",
        "    \"ratchet\" : \"rude\",\n",
        "    \"rbtl\" : \"read between the lines\",\n",
        "    \"rlrt\" : \"real life retweet\", \n",
        "    \"rofl\" : \"rolling on the floor laughing\",\n",
        "    \"roflol\" : \"rolling on the floor laughing out loud\",\n",
        "    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
        "    \"rt\" : \"retweet\",\n",
        "    \"ruok\" : \"are you ok\",\n",
        "    \"sfw\" : \"safe for work\",\n",
        "    \"sk8\" : \"skate\",\n",
        "    \"smh\" : \"shake my head\",\n",
        "    \"sq\" : \"square\",\n",
        "    \"srsly\" : \"seriously\", \n",
        "    \"ssdd\" : \"same stuff different day\",\n",
        "    \"tbh\" : \"to be honest\",\n",
        "    \"tbs\" : \"tablespooful\",\n",
        "    \"tbsp\" : \"tablespooful\",\n",
        "    \"tfw\" : \"that feeling when\",\n",
        "    \"thks\" : \"thank you\",\n",
        "    \"tho\" : \"though\",\n",
        "    \"thx\" : \"thank you\",\n",
        "    \"tia\" : \"thanks in advance\",\n",
        "    \"til\" : \"today i learned\",\n",
        "    \"tl;dr\" : \"too long i did not read\",\n",
        "    \"tldr\" : \"too long i did not read\",\n",
        "    \"tmb\" : \"tweet me back\",\n",
        "    \"tntl\" : \"trying not to laugh\",\n",
        "    \"ttyl\" : \"talk to you later\",\n",
        "    \"u\" : \"you\",\n",
        "    \"u2\" : \"you too\",\n",
        "    \"u4e\" : \"yours for ever\",\n",
        "    \"utc\" : \"coordinated universal time\",\n",
        "    \"w/\" : \"with\",\n",
        "    \"w/o\" : \"without\",\n",
        "    \"w8\" : \"wait\",\n",
        "    \"wassup\" : \"what is up\",\n",
        "    \"wb\" : \"welcome back\",\n",
        "    \"wtf\" : \"what the fuck\",\n",
        "    \"wtg\" : \"way to go\",\n",
        "    \"wtpa\" : \"where the party at\",\n",
        "    \"wuf\" : \"where are you from\",\n",
        "    \"wuzup\" : \"what is up\",\n",
        "    \"wywh\" : \"wish you were here\",\n",
        "    \"yd\" : \"yard\",\n",
        "    \"ygtr\" : \"you got that right\",\n",
        "    \"ynk\" : \"you never know\",\n",
        "    \"zzz\" : \"sleeping bored and tired\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RWkKdaD4UyH"
      },
      "outputs": [],
      "source": [
        "def word_abbrev(word):\n",
        "    return abbreviations[word] if word in abbreviations.keys() else word\n",
        "\n",
        "# Replace all abbreviations\n",
        "def replace_abbrev(text):\n",
        "    string = \"\"\n",
        "    for word in text.split():\n",
        "        string += word_abbrev(word) + \" \"        \n",
        "    return string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "To68FUbNB0Hl"
      },
      "outputs": [],
      "source": [
        "for n,i in df_train.iterrows():\n",
        "    text = i['tweet']\n",
        "    text = replace_abbrev(text)\n",
        "    text = remove_mention(text)\n",
        "    text = remove_elongated_words(text)\n",
        "    text = transcription_smile(text)\n",
        "    text = transcription_sad(text)\n",
        "    text = transcription_heart(text)\n",
        "    text = remove_repeat_punct(text)\n",
        "    # text = remove_all_punct(text)\n",
        "    df_train['tweet'][n] = text\n",
        "\n",
        "for n,i in df_dev.iterrows():\n",
        "    text = i['tweet']\n",
        "    text = replace_abbrev(text)\n",
        "    text = remove_mention(text)\n",
        "    text = remove_elongated_words(text)\n",
        "    text = transcription_smile(text)\n",
        "    text = transcription_sad(text)\n",
        "    text = transcription_heart(text)\n",
        "    text = remove_repeat_punct(text)\n",
        "    # text = remove_all_punct(text)\n",
        "    df_dev['tweet'][n] = text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wlGa0ph_Ufr"
      },
      "outputs": [],
      "source": [
        "for n,i in df_test.iterrows():\n",
        "    text = i['tweet']\n",
        "    text = replace_abbrev(text)\n",
        "    text = remove_mention(text)\n",
        "    text = remove_elongated_words(text)\n",
        "    text = transcription_smile(text)\n",
        "    text = transcription_sad(text)\n",
        "    text = transcription_heart(text)\n",
        "    text = remove_repeat_punct(text)\n",
        "    # text = remove_all_punct(text)\n",
        "    df_test['tweet'][n] = text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "T7QXcf5ULLDN",
        "outputId": "6ba5aea0-4506-4980-a9c8-45b26ffdd326"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cd447c99-b847-43be-95eb-2628f28e78a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>again he got killed for using false money</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>it's not that all lives don't matter</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>is it really that difficult to understand? bla...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>whenever we say black isn't that racists? why ...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ros the boss you don’t know that she’s actuall...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd447c99-b847-43be-95eb-2628f28e78a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cd447c99-b847-43be-95eb-2628f28e78a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cd447c99-b847-43be-95eb-2628f28e78a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               tweet            label\n",
              "0         again he got killed for using false money   Non_hope_speech\n",
              "1              it's not that all lives don't matter   Non_hope_speech\n",
              "2  is it really that difficult to understand? bla...  Non_hope_speech\n",
              "3  whenever we say black isn't that racists? why ...  Non_hope_speech\n",
              "4  ros the boss you don’t know that she’s actuall...  Non_hope_speech"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHZHmyPQ2ec9"
      },
      "outputs": [],
      "source": [
        "df_train.to_csv('/content/drive/MyDrive/Kaggle/Tweet_shared_task/df_train_preprocessed.csv')\n",
        "df_dev.to_csv('/content/drive/MyDrive/Kaggle/Tweet_shared_task/df_dev_preprocessed.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ll5tcn_z_b2i"
      },
      "outputs": [],
      "source": [
        "df_test.to_csv('/content/drive/MyDrive/Kaggle/Tweet_shared_task/df_new_test_preprocessed.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxiFI1XBM0Rl"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class LabelPredictionDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.samples = []\n",
        "        label_encodings = {'Non_hope_speech': 0, 'Hope_speech': 1}\n",
        "        for n,i in df.iterrows():\n",
        "            self.samples.append({\n",
        "                'tweet': i['tweet'],\n",
        "                'label': label_encodings[i['label']]\n",
        "            })\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laM1eiN0tWzG"
      },
      "outputs": [],
      "source": [
        "def encode(tweet: str):\n",
        "    encoding = tokenizer(tweet, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "    input_ids = encoding['input_ids']\n",
        "    attention_mask = encoding['attention_mask']\n",
        "    return input_ids, attention_mask\n",
        "\n",
        "def evaluate(model, dataset):\n",
        "    model.eval()\n",
        "    targets = []\n",
        "    outputs = []\n",
        "    with torch.no_grad():\n",
        "        for batch in DataLoader(dataset, batch_size=gpu_batch):\n",
        "            input_ids, attention_mask = encode(batch['tweet'])\n",
        "            logits = model(input_ids.to(device)).logits\n",
        "            targets.extend(batch['label'].float().tolist())\n",
        "            outputs.extend(logits.argmax(dim=1).tolist())\n",
        "    return {\n",
        "        'macro_f1': f1_score(targets, outputs, zero_division=0, average='macro'),\n",
        "        'f1': tuple(f1_score(targets, outputs, zero_division=0, average=None)),\n",
        "        'precision': tuple(precision_score(targets, outputs, zero_division=0, average=None)),\n",
        "        'recall': tuple(recall_score(targets, outputs, zero_division=0, average=None))\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtmQdrvJki3I"
      },
      "outputs": [],
      "source": [
        "trainset = LabelPredictionDataset(df_train)\n",
        "devset = LabelPredictionDataset(df_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-_nYCFwn3Rf",
        "outputId": "1a68bf8c-3627-4f57-f400-e7024ad8e92b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device \"cuda\"\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device \"{device}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNjP5qvptjCo"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_cosine_schedule_with_warmup\n",
        "# tokenizer = AutoTokenizer.from_pretrained('roberta-large-mnli')\n",
        "tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/Kaggle/Tweet_shared_task/roberta-large-mnli-epoch-3-f1-8032')\n",
        "# model = AutoModelForSequenceClassification.from_pretrained('roberta-large-mnli').to(device)\n",
        "model = AutoModelForSequenceClassification.from_pretrained('/content/drive/MyDrive/Kaggle/Tweet_shared_task/roberta-large-mnli-epoch-3-f1-8032').to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXZforT3oGFi"
      },
      "outputs": [],
      "source": [
        "batch_size = 1\n",
        "gpu_batch = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVyNSHIJna4T"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam([\n",
        "    {'params': model.roberta.parameters(), 'lr': 5e-5},\n",
        "    {'params': model.classifier.parameters(), 'lr': 1e-4}\n",
        "])\n",
        "checkpoint = torch.load('/content/drive/MyDrive/Kaggle/Tweet_shared_task/roberta-large-mnli-epoch-5-f1-7816/checkpoint.pt')\n",
        "optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, 128, 50 * batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "HwXhsEIKoL7A",
        "outputId": "dbdf10cd-1a15-433a-e507-edd1e39b5438"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6, iter 22739, loss: 0.001: 100%|██████████| 22740/22740 [46:43<00:00,  8.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 dev score:\n",
            "{'macro_f1': 0.7816901516248538, 'f1': (0.9501291476256706, 0.613251155624037), 'precision': (0.9703733766233766, 0.5278514588859416), 'recall': (0.9307123394316855, 0.7316176470588235)}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7, iter 22739, loss: 0.0004: 100%|██████████| 22740/22740 [46:30<00:00,  8.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 dev score:\n",
            "{'macro_f1': 0.7893909415788586, 'f1': (0.9541864139020537, 0.6245954692556634), 'precision': (0.9683366733466934, 0.5578034682080925), 'recall': (0.9404437524328533, 0.7095588235294118)}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8, iter 22739, loss: 0.0007: 100%|██████████| 22740/22740 [47:06<00:00,  8.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 dev score:\n",
            "{'macro_f1': 0.7828246229419353, 'f1': (0.951229183187946, 0.6144200626959248), 'precision': (0.9692929292929293, 0.5355191256830601), 'recall': (0.9338263915920592, 0.7205882352941176)}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9, iter 5886, loss: 0.0002:  26%|██▌       | 5887/22740 [12:15<35:06,  8.00it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-6270f8893f31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mgpu_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from typing import List\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, balanced_accuracy_score\n",
        "import os\n",
        "\n",
        "for e in range(6,50):\n",
        "  model.train()\n",
        "  t = tqdm(DataLoader(trainset, batch_size=gpu_batch, shuffle=True))\n",
        "  for i, batch in enumerate(t):\n",
        "      input_ids, attention_mask = encode(batch['tweet'])\n",
        "      outputs = model(input_ids=input_ids.to(device), attention_mask=attention_mask.to(device), labels=batch['label'].long().to(device))\n",
        "      loss = outputs.loss\n",
        "      loss.backward()\n",
        "      if (i + 1) % (batch_size // gpu_batch) == 0:\n",
        "          optimizer.step()\n",
        "          optimizer.zero_grad()\n",
        "          t.set_description(f'Epoch {e}, iter {i}, loss: {round(loss.item(), 4)}')\n",
        "  scheduler.step()\n",
        "  checkpoint = {\n",
        "    'epoch': e + 1,\n",
        "    'optimizer': optimizer.state_dict()\n",
        "  }\n",
        "  # Eval\n",
        "#   train_score = evaluate(model, trainset)\n",
        "#   print(f'Epoch {e} train score:')\n",
        "#   print(train_score)\n",
        "  dev_score = evaluate(model, devset)\n",
        "  print(f'Epoch {e} dev score:')\n",
        "  print(dev_score)\n",
        "\n",
        "  # Save\n",
        "  save_path = os.path.join('/content/drive/MyDrive/Kaggle/Tweet_shared_task', f'roberta-large-mnli-epoch-{e}-f1-{int(dev_score[\"macro_f1\"] * 1e4)}')\n",
        "  os.makedirs(save_path)\n",
        "  tokenizer.save_pretrained(save_path)\n",
        "  model.save_pretrained(save_path)\n",
        "  torch_save_path = save_path+'/checkpoint.pt'\n",
        "  torch.save(checkpoint,torch_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvLfNrX9IODH",
        "outputId": "2a50a4d3-9593-4be6-ebae-70974859ac64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device \"cuda\"\n",
            "388it [00:18, 20.97it/s]\n"
          ]
        }
      ],
      "source": [
        "!python label.py \\\n",
        "--dataset '/content/drive/MyDrive/Kaggle/Tweet_shared_task/df_new_test_preprocessed.csv' \\\n",
        "--model '/content/drive/MyDrive/Kaggle/Tweet_shared_task/roberta-large-mnli-epoch-3-f1-8032' \\\n",
        "--output 'new_test_results.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbqoWvyOJDGp"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('new_test_results.csv')\n",
        "df = pd.DataFrame({'id':df['Unnamed: 0'], 'text':df['tweet'],'label':df['label']})\n",
        "df.to_csv('new_test_results.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yAoXjp1NQKL0",
        "outputId": "fcbdd54d-5695-4d13-cc51-dbc24b4ad14d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ea1addcd-103d-41c4-bc69-03d77abb0a10\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>what do you mean by the word sniped?i love thi...</td>\n",
              "      <td>Hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>what do you mean by the word sniped?ya the iro...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>what do you mean by the word sniped?a person's...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>what do you mean by the word sniped? of gasters</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>what do you mean by the word sniped?i bet if t...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea1addcd-103d-41c4-bc69-03d77abb0a10')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ea1addcd-103d-41c4-bc69-03d77abb0a10 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ea1addcd-103d-41c4-bc69-03d77abb0a10');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id                                               text            label\n",
              "0   0  what do you mean by the word sniped?i love thi...      Hope_speech\n",
              "1   1  what do you mean by the word sniped?ya the iro...  Non_hope_speech\n",
              "2   2  what do you mean by the word sniped?a person's...  Non_hope_speech\n",
              "3   3   what do you mean by the word sniped? of gasters   Non_hope_speech\n",
              "4   4  what do you mean by the word sniped?i bet if t...  Non_hope_speech"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('test_results.tsv', sep='\\t')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embeddings"
      ],
      "metadata": {
        "id": "pbaWgjOpxtnR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6EQcn5RqRFV9"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5KYsequ2WU6"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm\n",
        "!pip install summa\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install sklearn\n",
        "!pip install keras\n",
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import bert\n",
        "from bert import BertModelLayer\n",
        "from bert.loader import StockBertConfig , map_stock_config_to_params , load_stock_weights\n",
        "from bert.tokenization.bert_tokenization import FullTokenizer\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, TimeDistributed, AveragePooling2D, Lambda, Softmax, Dense, Flatten, Embedding, Bidirectional, LSTM, Dropout, Input, Reshape, concatenate, dot, Multiply, RepeatVector\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import time\n",
        "from copy import deepcopy\n",
        "import random\n",
        "\n",
        "seed = 1\n",
        " \n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n"
      ],
      "metadata": {
        "id": "ofz6i2g3x5pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/tweets_english_train.csv\"\n",
        "sentences = pd.read_csv(data_path)\n",
        "sentences = sentences[['Text']]\n",
        "xyz = [i%2 for i in range(len(sentences))]\n",
        "sentences['decision'] = xyz\n",
        "sentences.columns = ['text' , 'decision']\n",
        "tmp=[[sentences['text'][i],sentences['decision'][i]] for i in range(3)]\n",
        "tmp = pd.DataFrame(tmp, columns=['text' , 'decision'])"
      ],
      "metadata": {
        "id": "kadkjDnDx8k1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bert_model..............................................\n",
        "bert_model_name = \"roberta\"\n",
        "bert_ckpt_dir = os.path.join(bert_model_name)\n",
        "bert_ckpt_file = os.path.join(bert_ckpt_dir,\"bert_model.ckpt\")\n",
        "bert_config_file = os.path.join(bert_ckpt_dir,\"bert_config.json\")\n",
        "\n",
        "print(\"bert chekpoint dir : \",bert_ckpt_dir)\n",
        "print(\"bert chekpoint file : \",bert_ckpt_file)\n",
        "print(\"bert config dir : \",bert_config_file)\n",
        "\n",
        "tokenizer = FullTokenizer(vocab_file=os.path.join(bert_ckpt_dir, \"vocab.txt\"))\n",
        "\n",
        "class PaperData:\n",
        "\tDATA_COLUMN = \"text\"\n",
        "\tLABEL_COLUMN = \"decision\"\n",
        "\tdef __init__(self, train, test, tokenizer: FullTokenizer, classes, max_seq_len=16000):\n",
        "\t\tself.tokenizer = tokenizer\n",
        "\t\tself.max_seq_len = 0\n",
        "\t\t((self.train_x, self.train_y), (self.test_x, self.test_y)) =\\\n",
        "\t\t\tmap(self._prepare, [train, test])\n",
        "\t\tself.max_seq_len = min(self.max_seq_len, max_seq_len)\n",
        "\t\t\n",
        "\tdef _prepare(self, df):\n",
        "\t\tx, y = [], []\n",
        "\t\tfor _, row in tqdm(df.iterrows()):\n",
        "\t\t\ttext, label =\\\n",
        "\t\t\t\trow[PaperData.DATA_COLUMN], row[PaperData.LABEL_COLUMN]\n",
        "\t\t\ttokens = self.tokenizer.tokenize(text)\n",
        "\t\t\ttokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
        "\t\t\ttoken_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "\t\t\tself.max_seq_len = max(self.max_seq_len, len(token_ids))\n",
        "\t\t\tx.append(token_ids)\n",
        "\t\t\ty.append(classes.index(label))\n",
        "\t\treturn np.array(x), np.array(y)\n",
        "\t\t\n",
        "def pad_sbert(ids,msl):\n",
        "\tx = []\n",
        "\tfor input_ids in ids:\n",
        "\t\tinput_ids = input_ids[:min(len(input_ids), msl)]\n",
        "\t\tinput_ids = input_ids + [0] * (msl - len(input_ids))\n",
        "\t\tx.append(np.array(input_ids))\n",
        "\treturn np.array(x)\n",
        "\t\n",
        "def create_model(max_seq_len, bert_ckpt_file):\n",
        "\twith tf.io.gfile.GFile(bert_config_file, \"r\") as reader:\n",
        "\t\tbc = StockBertConfig.from_json_string(reader.read())\n",
        "\t\tbert_params = map_stock_config_to_params(bc)\n",
        "\t\tbert_params.adapter_size = None\n",
        "\t\tbert = BertModelLayer.from_params(bert_params, name=\"bert\")\n",
        "\tinput_ids = Input(shape=(max_seq_len, ), dtype='int32', name=\"input_ids\")\n",
        "\tbert_output = bert(input_ids)\n",
        "\t\n",
        "\tcls_out = Lambda(lambda seq: seq[:, 0, :])(bert_output)\n",
        "\t#logits = Dense(units=100, activation=\"tanh\")(cls_out)\n",
        "\t#logits = Dropout(0.5)(logits)\n",
        "\t#logits = Dense(units=len(classes), activation=\"softmax\")(logits)\n",
        "\t\n",
        "\tmodel = Model(inputs=input_ids, outputs=cls_out)\n",
        "\tmodel.build(input_shape=(None, max_seq_len))\n",
        "\tload_stock_weights(bert, bert_ckpt_file)\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "H4zZn3BgyLa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=======Tokenizing Sentences=======\\n\")\n",
        "classes = sentences.decision.unique().tolist()\n",
        "data = PaperData(sentences, tmp, tokenizer, classes, max_seq_len=1500)"
      ],
      "metadata": {
        "id": "54ExNaHOyUuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_dvs = 500\n",
        "data_dvs = [[] for i in range(num_dvs)]\n",
        "dataMeta = [[] for i in range(num_dvs)]\n",
        "num_tokens = len(sentences)\n",
        "for i in range(num_tokens):\n",
        "\tdata_dvs[(24+len(data.train_x[i]))//25].append(data.train_x[i])\n",
        "\tdataMeta[(24+len(data.train_x[i]))//25].append(i)"
      ],
      "metadata": {
        "id": "Cmv18jTdyWSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=======Generating Embeddings=======\\n\")\n",
        "def tk_avg(lst):\n",
        "\tln = len(lst)\n",
        "\tdm = len(lst[0])\n",
        "\tret = [0.0 for i in range(dm)]\n",
        "\tfor x in lst:\n",
        "\t\tfor i in range(dm):\n",
        "\t\t\tret[i] += x[i]\n",
        "\tfor i in range(dm):\n",
        "\t\tret[i] = ret[i]/ln\n",
        "\treturn ret\n",
        "\n",
        "data2embed = []\n",
        "Edata = [[] for i in range(num_tokens)]\n",
        "for i in tqdm(range(1,num_dvs) , desc=\"processing\t\t\"):\n",
        "\tprint(\"Batch : [\",i,\"/\",num_dvs,\"] -------------------\")\n",
        "\tif len(data_dvs[i])==0:\n",
        "\t\tcontinue\n",
        "\ttoken_sz = i*25\n",
        "\tflag = False\n",
        "\td2eMeta = []\n",
        "\tdata2embed = []\n",
        "\tst = 0\n",
        "\tif (i*25)>512:\n",
        "\t\tflag = True\n",
        "\t\tnt = (i*25)//512\n",
        "\t\tnt = (i*25)//(nt+1)\n",
        "\t\tfor z in data_dvs[i]:\n",
        "\t\t\tlst = []\n",
        "\t\t\tc = 0\n",
        "\t\t\ttlen = len(z)\n",
        "\t\t\tfor k in range(tlen):\n",
        "\t\t\t\tlst.append(z[k])\n",
        "\t\t\t\tif len(lst)==nt:\n",
        "\t\t\t\t\tdata2embed.append(deepcopy(lst))\n",
        "\t\t\t\t\tc += 1\n",
        "\t\t\t\t\tlst = []\n",
        "\t\t\tif len(lst)>0:\n",
        "\t\t\t\tdata2embed.append(deepcopy(lst))\n",
        "\t\t\t\tc += 1\n",
        "\t\t\td2eMeta.append([st , st+c])\n",
        "\t\t\tst += c\n",
        "\t\tdata2embed = pad_sbert(data2embed,nt)\n",
        "\t\ttoken_sz = nt\n",
        "\telse:\n",
        "\t\tdata2embed = pad_sbert(data_dvs[i],i*25)\n",
        "\tmodel = create_model(token_sz, bert_ckpt_file)\n",
        "\tmodel.compile(optimizer=keras.optimizers.Adam(1e-5), loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")])\n",
        "\t\n",
        "\tpredict_y = model.predict(data2embed,verbose=1,batch_size=10)\n",
        "\tpredict_y = predict_y.tolist()\n",
        "\tif flag==True:\n",
        "\t\tfpy = []\n",
        "\t\tfor x in d2eMeta:\n",
        "\t\t\tlst = []\n",
        "\t\t\tfor k in range(x[0],x[1]):\n",
        "\t\t\t\tlst.append(predict_y[k])\n",
        "\t\t\tlst = tk_avg(lst)\n",
        "\t\t\tfpy.append(deepcopy(lst))\n",
        "\t\tpredict_y = deepcopy(fpy)\n",
        "\tln = len(predict_y)\n",
        "\tfor j in range(ln):\n",
        "\t\tEdata[dataMeta[i][j]] = deepcopy(predict_y[j])"
      ],
      "metadata": {
        "id": "gqvqUuyryXys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=======Dimension Cheking=======\\n\")\n",
        "num_tokens = len(sentences)\n",
        "print(\"Embedding matrix-size (num of toxens * embed_dim) : [\",num_tokens,\"] : \",len(Edata),\" * 768\")\n",
        "for i in range(num_tokens):\n",
        "\tif len(Edata[i])!=768:\n",
        "\t\tprint(\"ERROR : Dimension uneven.\")\n",
        "\t\tbreak"
      ],
      "metadata": {
        "id": "OQXKbSyiyaDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attention"
      ],
      "metadata": {
        "id": "qd9j8P3myct6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import time\n",
        "from copy import deepcopy\n",
        "import random\n",
        "from tensorflow.keras.layers import Conv2D, Bidirectional,Permute , Dot, MaxPooling2D, TimeDistributed, AveragePooling2D, Lambda, Softmax, Dense, Flatten, Embedding, Bidirectional, LSTM, Dropout, Input, Reshape, concatenate, dot, Multiply, RepeatVector, Activation\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn import metrics\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "from keras.layers import Layer\n",
        "import keras.backend as K\n",
        "from keras.layers import Input, Dense, SimpleRNN\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.metrics import mean_squared_error\n",
        "\n",
        "seed = 9999\n",
        " \n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ],
      "metadata": {
        "id": "49DzLUGwyfOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtr, xte, ytr, yte = train_test_split(x,y, test_size=0.25, random_state=1, stratify=y)\n",
        "print(\"train size : \", len(ytr))\n",
        "print(\"test size : \", len(yte))"
      ],
      "metadata": {
        "id": "2Bhj_FzQyk4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def balance_batch(batch_size, x, y):\n",
        "  cx = [[], []]\n",
        "  n = len(y)\n",
        "  for i in range(n):\n",
        "    cx[int(y[i])].append(x[i])\n",
        "  random.shuffle(cx[0])\n",
        "  random.shuffle(cx[1])\n",
        "  p_ids = []\n",
        "  ix = [0, 0]\n",
        "  while ix[0]!=len(cx[0]):\n",
        "    p_ids.append(cx[0][ix[0]])\n",
        "    ix[0]+=1\n",
        "    p_ids.append(cx[1][ix[1]])\n",
        "    ix[1]+=1\n",
        "    ix[1] = ix[1]%(len(cx[1]))\n",
        "  return p_ids"
      ],
      "metadata": {
        "id": "elnIlXcUyshf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse_fun(pred,actual):\n",
        "\treturn np.sqrt(np.mean((pred-actual)**2))\n",
        " \n",
        "@tf.function\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "\treturn K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
        " \n",
        "# tf.keras.losses.BinaryCrossentropy(\n",
        "#     from_logits=False, label_smoothing=0, axis=-1,\n",
        "#     reduction=losses_utils.ReductionV2.AUTO, name='binary_crossentropy'\n",
        "# )\n",
        "BinaryCrossentropy = tf.keras.losses.BinaryCrossentropy()"
      ],
      "metadata": {
        "id": "jOk-1-Plytt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "activation_func = \"relu\"\n",
        "dropout = 0.7\n",
        "units = 200"
      ],
      "metadata": {
        "id": "9FVNQZG4yxSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_model = None\n",
        "def model_architectureNPM():  \n",
        "  #paper - part\n",
        "  paper_input = Input(shape=(paper_mx_sections,))\n",
        "  paper_embedded = Embedding(paper_num_tokens, paper_embed_dim, embeddings_initializer=tf.keras.initializers.Constant(paperEmbed), trainable=False)(paper_input)\n",
        "\n",
        "  ##paper only - cnn\n",
        "  SC = Reshape((paper_mx_sections,paper_embed_dim,1))(paper_embedded)\n",
        "\n",
        "  p_a = Conv2D(paper_num_filters, (1,paper_embed_dim),activation=activation_func)(SC)\n",
        "  p_a = MaxPooling2D(pool_size=(paper_mx_sections,1))(p_a)\n",
        "  p_a = Flatten()(p_a)\n",
        "\n",
        "  p_b = Conv2D(paper_num_filters, (2,paper_embed_dim),activation=activation_func)(SC)\n",
        "  p_b = MaxPooling2D(pool_size=(paper_mx_sections-1,1))(p_b)\n",
        "  p_b = Flatten()(p_b)\n",
        "\n",
        "  p_c = Conv2D(paper_num_filters, (3,paper_embed_dim),activation=activation_func)(SC)\n",
        "  p_c = MaxPooling2D(pool_size=(paper_mx_sections-2,1))(p_c)\n",
        "  p_c = Flatten()(p_c)\n",
        "\n",
        "  p_d = Conv2D(paper_num_filters, (4,paper_embed_dim),activation=activation_func)(SC)\n",
        "  p_d = MaxPooling2D(pool_size=(paper_mx_sections-3,1))(p_d)\n",
        "  p_d = Flatten()(p_d)\n",
        "\n",
        "  p_e = Conv2D(paper_num_filters, (5,paper_embed_dim),activation=activation_func)(SC)\n",
        "  p_e = MaxPooling2D(pool_size=(paper_mx_sections-4,1))(p_e)\n",
        "  p_e = Flatten()(p_e)\n",
        "\n",
        "  sc = concatenate([p_a , p_b , p_c , p_d , p_e] , axis=-1)\n",
        "  sc_final = Flatten()(sc)\n",
        "  sc_final = Dropout(dropout)(sc_final)\n",
        "\n",
        "  sc_vector = Flatten()(sc_final)\n",
        "  \n",
        "  # Self Attention On Reviews -------------------------------------------------------------------------\n",
        "  # activations = TimeDistributed(LSTM(64, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))(rev_embedded)\n",
        "  activations = TimeDistributed(Bidirectional(LSTM(units, return_sequences=True)))(rev_embedded)\n",
        "\n",
        "  # attention\n",
        "  attention = TimeDistributed(Dense(1, activation='tanh'))(activations) \n",
        "  attention = TimeDistributed(Flatten())(attention)\n",
        "  attention = TimeDistributed(Activation('softmax'), name=\"attention_vec\")(attention)\n",
        "  attention = TimeDistributed(RepeatVector(2*units))(attention)\n",
        "  attention = TimeDistributed(Permute([2, 1]))(attention)\n",
        "\n",
        "  representation_activations = Multiply()([activations, attention])\n",
        "  # representation_activations = Lambda(lambda xin: K.sum(xin, axis=0))(representation_activations)\n",
        "  representation_activations = Lambda(lambda xin: K.sum(xin, axis=-2), output_shape=(units,))(representation_activations)\n",
        "  activations = TimeDistributed(Flatten())(representation_activations)\n",
        "\n",
        "  # rev only - cnn--------------------------------------------------------------------------\n",
        "  \n",
        "  R = Reshape((3,rev_mx_snts,rev_embed_dim,1))(rev_embedded)\n",
        "\n",
        "  r_a = TimeDistributed(Conv2D(rev_num_filters, (1,rev_embed_dim),activation=activation_func), name=\"r_a\")(R)\n",
        "  r_a = TimeDistributed(MaxPooling2D(pool_size=(rev_mx_snts,1)))(r_a)\n",
        "  r_a = TimeDistributed(Flatten())(r_a)\n",
        "\n",
        "  r_b = TimeDistributed(Conv2D(rev_num_filters, (2,rev_embed_dim),activation=activation_func))(R)\n",
        "  r_b = TimeDistributed(MaxPooling2D(pool_size=(rev_mx_snts-1,1)))(r_b)\n",
        "  r_b = TimeDistributed(Flatten())(r_b)\n",
        "\n",
        "  r_c = TimeDistributed(Conv2D(rev_num_filters, (3,rev_embed_dim),activation=activation_func))(R)\n",
        "  r_c = TimeDistributed(MaxPooling2D(pool_size=(rev_mx_snts-2,1)))(r_c)\n",
        "  r_c = TimeDistributed(Flatten())(r_c)\n",
        "\n",
        "  r_d = TimeDistributed(Conv2D(rev_num_filters, (4,rev_embed_dim),activation=activation_func))(R)\n",
        "  r_d = TimeDistributed(MaxPooling2D(pool_size=(rev_mx_snts-3,1)))(r_d)\n",
        "  r_d = TimeDistributed(Flatten())(r_d)\n",
        "\n",
        "  r_e = TimeDistributed(Conv2D(rev_num_filters, (5,rev_embed_dim),activation=activation_func))(R)\n",
        "  r_e = TimeDistributed(MaxPooling2D(pool_size=(rev_mx_snts-4,1)))(r_e)\n",
        "  r_e = TimeDistributed(Flatten())(r_e)\n",
        "\n",
        "  r_f = TimeDistributed(Conv2D(rev_num_filters, (6,rev_embed_dim),activation=activation_func))(R)\n",
        "  r_f = TimeDistributed(MaxPooling2D(pool_size=(rev_mx_snts-5,1)))(r_f)\n",
        "  r_f = TimeDistributed(Flatten())(r_f)\n",
        "\n",
        "  r_g = TimeDistributed(Conv2D(rev_num_filters, (7,rev_embed_dim),activation=activation_func))(R)\n",
        "  r_g = TimeDistributed(MaxPooling2D(pool_size=(rev_mx_snts-6,1)))(r_g)\n",
        "  r_g = TimeDistributed(Flatten())(r_g)\n",
        "\n",
        "  r = concatenate([r_a , r_b , r_c , r_d , r_e , r_f , r_g] , axis=-1)\n",
        "  r_final = TimeDistributed(Flatten())(r) #shape 3,x\n",
        "  r_final = TimeDistributed(Dropout(dropout))(r_final)\n",
        "  r_final = concatenate([r_final,vader_flat,activations] , axis=-1) #3,x+y\n",
        "\n",
        "  r_vector = Flatten()(r_final) # CNN on reviews embedding\n",
        "\n",
        "  #Recommedation\n",
        "  sc_final = RepeatVector(3)(sc_vector)\n",
        "  rec_inp = concatenate([r_final, sc_final] , axis=-1)\n",
        "  rec_dim1 = Dense(d_out,activation=\"relu\")(rec_inp)\n",
        "  rec_dim1 = Dropout(dropout)(rec_dim1)\n",
        "  rec_dim2 = Dense(d_out,activation=\"softsign\")(rec_inp)\n",
        "  rec_dim2 = Dropout(dropout)(rec_dim2)\n",
        "  rec_dim3 = Dense(d_out,activation=\"sigmoid\")(rec_inp)\n",
        "  rec_dim3 = Dropout(dropout)(rec_dim3)\n",
        "\n",
        "  rec_dim = concatenate([rec_dim1 , rec_dim2 , rec_dim3] , axis=-1)\n",
        "  rec_out = Dense(1,activation=\"relu\")(rec_dim)\n",
        "  rec_out = Flatten(name=\"Regression_Output\")(rec_out)\n",
        "\n",
        "  #MLP\n",
        "  mlp_inp = concatenate([r_vector, sc_vector] , axis=-1)\n",
        "\n",
        "  dim1 = Dense(d_out,activation=\"relu\")(mlp_inp)\n",
        "  dim1 = Dropout(dropout)(dim1)\n",
        "  dim2 = Dense(d_out,activation=\"softsign\")(mlp_inp)\n",
        "  dim2 = Dropout(dropout)(dim2)\n",
        "  dim3 = Dense(d_out,activation=\"sigmoid\")(mlp_inp)\n",
        "  dim3 = Dropout(dropout)(dim3)\n",
        "\n",
        "  dim = concatenate([dim1 , dim2 , dim3] , axis=-1)\n",
        "  classification_out = Dense(1,activation=\"sigmoid\", name=\"Classification_Output\")(dim)\n",
        "\n",
        "  model = Model(inputs=[paper_input, rev_input, vader_input] , outputs=[classification_out,rec_out])\n",
        "  model.compile(optimizer = \"adam\", loss = [BinaryCrossentropy, root_mean_squared_error] ,metrics =[\"accuracy\",\"mse\"])\n",
        "\n",
        "  cls_model = Model(inputs=[paper_input, rev_input, vader_input] , outputs=classification_out)\n",
        "  cls_model.compile(optimizer = \"adam\", loss = BinaryCrossentropy ,metrics =[\"accuracy\"])\n",
        "\n",
        "  global attention_model\n",
        "  attention_model = Model(inputs=[paper_input, rev_input, vader_input] , outputs=model.get_layer('attention_vec').output)\n",
        "\n",
        "  return cls_model,rec_model,model"
      ],
      "metadata": {
        "id": "e1Lv2T90y1cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Only Attention\n",
        "import copy\n",
        "teLen = len(tc)\n",
        "min_rmse = 18.0\n",
        "trc_prd = []\n",
        "attention_values = None\n",
        "for i in range(48):\n",
        "  print(\"Epoch:\",i)\n",
        "  attn.fit(train_inputs, yrc, batch_size = 32, shuffle=False,epochs = 1,verbose=1)\n",
        "  rec_tmp = attn.predict(test_inputs)\n",
        "  RMSE=rmse_fun(rec_tmp,trc)\n",
        "  if RMSE<min_rmse:\n",
        "    min_rmse = RMSE\n",
        "    trc_prd = copy.deepcopy(rec_tmp)\n",
        "    # attention_values = attention_model.predict(test_inputs)\n",
        "  print(\"RMSE:\", RMSE)"
      ],
      "metadata": {
        "id": "o9H2ym1gz0-F"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Hope Speech Github.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}